{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eScience Incubator Project: Data Analytics for Demixing and Decoding Patterns of Population Neural Activity Underlying Addiction Behavior \n",
    "\n",
    "### Charles Zhou, Research Scientist at the Center in Neurobiology of Addiction, Pain, and Emotion\n",
    "\n",
    "The aim of this project is to apply novel statistical and machine learning analysis techniques to large-scale 2-photon calcium imaging data with respect to addiction-related behaviors and assays.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](fig1.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import h5py\n",
    "import tensortools as tt # toolbox for TCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle # for loading behav data\n",
    "import importlib as imp\n",
    "import os\n",
    "\n",
    "# import scripts that CZ has written\n",
    "import utils\n",
    "import load_preprocess_data # takes motion corrected h5 data and behav data and creates trial-resolved xarrays for analysis\n",
    "\n",
    "import xarray # for organizing and storing the data \n",
    "import pandas as pd\n",
    "from sklearn_xarray import wrap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# 3d state space plot\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm    \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "import matplotlib\n",
    "# important for text to be detecting when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate a file to analyze\n",
    "fname = 'VJ_OFCVTA_7_260_D6'\n",
    "fdir = r'D:\\olympus_data\\Vijay data\\VJ_OFCVTA_7_D8_trained'\n",
    "sima_h5_path = os.path.join(fdir, fname + '_sima_mc.h5')\n",
    "\n",
    "# set the sampling rate\n",
    "fs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and preprocessing the data\n",
    "\n",
    "The data are in h5 (HDF5) format, which has the advantage of being able to load portions of the data into memory at a time. Below, we load the data, reorganize the dimensions, and convert it into x-array format. X-array is a python-unique data structure that allows for storage of meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h5file = h5py.File(os.path.join(fdir, fname+'.h5'), 'r')\n",
    "data_h5file['imaging'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some meta data\n",
    "data_dims = data_h5file['imaging'].shape\n",
    "tvec = np.linspace(0, data_dims[2]/fs, data_dims[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the first frame from the video snippit\n",
    "frame_num = 0\n",
    "to_plot = data_h5file['imaging'][frame_num,:,:]\n",
    "\n",
    "utils.plot_single_img(to_plot, frame_num) # function in custom code utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the behavioral data.\n",
    "\n",
    "During the brain recordings, animals perform a behavioral task (pavlovian conditioning) that allows for understanding how neural activity gives rise to memory encoding of rewards. The significance of examining this behavior is that addiction states are heavily based on associating a drug (unconditioned stimulus - US) to a particular cue (eg. heroin needle; conditioned stimulus - CS).\n",
    "\n",
    "The figure below (Namboodiri et al., 2019 Nature Neuroscience) shows the recording setup and task:\n",
    "\n",
    "![alt text](namboodiri_nn_fig1ab.png \"Title\")\n",
    "\n",
    "\n",
    "Across the whole recording session, the animal is presented with randomized stimuli paired with or without sucrose rewards (each presentation is considered a trial). The time (ie. sample) at which each trial occurs relative to the beginning of the session is recorded and saved in a pickle file.\n",
    "\n",
    "We ultimately want to reshape the data for a certain session (typically y_pixels, x_pixels, time/samples) to be amenable to trial-by-trial classifcation in a neural network. The resulting reshaped dimensions will be: trial, y_pixels, x_pixels, time/samples. So for a session with two behavioral conditions 50 trials each, 512x512, and 3 second trials (at 5 hz, that's 15 samples), our resulting array/tensor will be: 100 x 512 x 512 x 15. \n",
    "\n",
    "Since we have orders of magnitude more values for x and y pixels than samples, we will ultimately be performing dimensionality reduction to make the dataset more tractable. We will perform dimensionality reduction across y_pixels, x_pixels, and time/samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial windowing \n",
    "trial_start_end_seconds = np.array([-1, 3]) # trial windowing in seconds relative to ttl-onset/trial-onset\n",
    "conditions = ['minus', 'plus_rewarded']\n",
    "\n",
    "# if helper scripts have been updated, can refresh them with this line\n",
    "imp.reload(utils)\n",
    "imp.reload(load_preprocess_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn trial-extracted data to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(load_preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_avg_groups = 5.0 \n",
    "\"\"\" number of segments to split trials over. Ie. Because single trial plots in state space is noisy, \n",
    "    let's break the trials up into groups and average to get less noisier signal.\n",
    "\"\"\" \n",
    "\n",
    "data_dict = load_preprocess_data.load(fname, fdir, fs, trial_start_end_seconds, conditions, num_avg_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PCA Dimensionality Reduction Across Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "variance_thresh = 0.9\n",
    "pca_xr_wrapper = wrap(PCA(variance_thresh), reshapes='yx', random_state=5) # create PCA object and specify dimension to perform PCA on\n",
    "\n",
    "# fit PCA on trial and condition-averaged data; final dims are pixels by time\n",
    "data_dict['all_cond']['Xt'] = pca_xr_wrapper.fit_transform( data_dict['all_cond']['flattenpix_trial_cond_avg'].transpose() )\n",
    "\n",
    "for condition in conditions:\n",
    "    \n",
    "    data_dict[condition]['Xt'] = pca_xr_wrapper.transform(data_dict[condition]['xarr_flatten_pix_trialAvg'].transpose())\n",
    "    \n",
    "    data_dict[condition]['pca_explained_var_perc'] = pca_xr_wrapper.estimator_.explained_variance_ratio_*100\n",
    "\n",
    "\n",
    "num_comps = pca_xr_wrapper.estimator_.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_ticks = range(0,num_comps)\n",
    "ax.bar(x_ticks, data_dict[condition]['pca_explained_var_perc'])\n",
    "ax.set_title('Variance Explained For Each PC', fontsize = 20)\n",
    "ax.set_ylabel('Variance Explained [%]', fontsize = 20)\n",
    "ax.set_xlabel('PC #', fontsize = 20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(data_dict['trial_tvec'], data_dict['minus']['Xt'][:,:3])\n",
    "plt.title('Time-Course of First PCs', fontsize = 15)\n",
    "plt.ylabel('Fluorescence', fontsize = 15)\n",
    "plt.xlabel('Time', fontsize = 15)\n",
    "plt.legend(['PC0', 'PC1', 'PC2'], fontsize = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform individual trial data into trial-avg PC space\n",
    "\n",
    "for condition in conditions:\n",
    "\n",
    "    trial_data = data_dict[condition]['xarr_flatten_xy_group_trials']\n",
    "    num_trials = trial_data.shape[0]\n",
    "    \n",
    "    trial_nparray = np.empty([num_trials, data_dict[condition]['num_samples'], num_comps])\n",
    "    \n",
    "    for idx, trial_dat in enumerate(trial_data):\n",
    "        \n",
    "        trial_nparray[idx,:,:] = pca_xr_wrapper.transform(trial_dat.transpose())\n",
    "    \n",
    "    data_dict[condition]['Xt_trial'] = trial_nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares list of old limits to new limits; replaces limits if new limits are outside of old\n",
    "def update_lims(new_lims, old_lims = None):\n",
    "    \n",
    "    updated_lims = np.empty_like(new_lims)\n",
    "    \n",
    "    for min_max in [0, 1]: # indices where 0 for min, 1 for max\n",
    "        \n",
    "        if old_lims is None:\n",
    "            updated_lims[min_max] = new_lims[min_max]\n",
    "        else:\n",
    "            compare = [old_lims[min_max], new_lims[min_max]]\n",
    "            updated_lims[min_max] = compare[np.argmax(np.abs(compare))]\n",
    "\n",
    "    return updated_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_3d_state_space():\n",
    "    \n",
    "    def __init__(self, x, y, z):\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line_collection(x, y, z, color_encode, cmap, trial = False, alpha = 1.0):\n",
    "\n",
    "    # Create a set of line segments\n",
    "    points = np.array([x, y, z]).T.reshape(-1, 1, 3)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create the 3D-line collection object\n",
    "    lc = Line3DCollection(segments, cmap=plt.get_cmap(cmap),\n",
    "                        norm=plt.Normalize(np.min(color_encode), np.max(color_encode))) # set LUT for segment colors\n",
    "    lc.set_array(color_encode) # set the dimension and values for color encoding\n",
    "    \n",
    "    \n",
    "    # all trial averaged lines will have markers\n",
    "    if trial == False:\n",
    "        lc.set_linestyle(':')\n",
    "        lc.set_linewidth(4)\n",
    "        \n",
    "    # trial group lines should encode segment number in alpha\n",
    "    if trial == True:\n",
    "        lc.set_alpha(alpha)\n",
    "        lc.set_linewidth(1.5)\n",
    "        \n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# container to store data relevant to the 3d plot\n",
    "s_space_dict = {}\n",
    "s_space_dict['line_cmaps'] = ['autumn','winter']\n",
    "\n",
    "# determine alpha for each trial (encoding time block)\n",
    "trial_group_alphas = np.linspace(0.3, 1, num_avg_groups)\n",
    "\n",
    "# loop through conditions\n",
    "for idx_condition, condition in enumerate(conditions):\n",
    "\n",
    "    # set up variables for this condition\n",
    "    s_space_dict[condition] = {} # sub-dict for condition-specific data \n",
    "    n = data_dict[condition]['num_samples'] # number of data points\n",
    "    cmap_lc = s_space_dict['line_cmaps'][idx_condition] # grab this condition's line cmap\n",
    "    \n",
    "    #set x,y,z, time data\n",
    "    x = data_dict[condition]['Xt'][:,0]\n",
    "    y = data_dict[condition]['Xt'][:,1]\n",
    "    z = data_dict[condition]['Xt'][:,2]\n",
    "    svec = np.arange(0,n) # sample vector; important for encoding color as time\n",
    "    # USER DEFINE: which dimension to encode color; can be x, y, z, svec\n",
    "    color_encode = svec \n",
    "    \n",
    "    # update x,y,z limits based on this condition's data\n",
    "    if idx_condition == 0:\n",
    "        xlim = [np.min(x), np.max(x)]; ylim = [np.min(y), np.max(y)]; zlim = [np.min(z), np.max(z)]\n",
    "    else:\n",
    "        xlim = update_lims([np.min(x), np.max(x)], xlim); \n",
    "        ylim = update_lims([np.min(y), np.max(y)], ylim); \n",
    "        zlim = update_lims([np.min(z), np.max(z)], zlim);\n",
    "    \n",
    "    ### Create line segment objects for ALL TRIAL-AVGED DATA ###\n",
    "    s_space_dict[condition]['line_collect'] = make_line_collection(x, y, z, color_encode, cmap_lc)\n",
    "    \n",
    "    ### Create line segment objects for TRIAL-BLOCKED/GROUPED DATA ###\n",
    "    s_space_dict[condition]['line_collect_trial'] = {}\n",
    "    for idx, trial in enumerate(data_dict[condition]['Xt_trial']):\n",
    "        \n",
    "        # make the line segment object for this trial group\n",
    "        s_space_dict[condition]['line_collect_trial'][idx] = make_line_collection(trial[:,0], trial[:,1], trial[:,2], \n",
    "                                                                                  color_encode, \n",
    "                                                                                  cmap_lc, \n",
    "                                                                                  trial = True, \n",
    "                                                                                  alpha = trial_group_alphas[idx])\n",
    "\n",
    "        # update x,y,z limits based on this \"trial's\" data\n",
    "        xlim = update_lims([np.min(trial[:,0]), np.max(trial[:,0])], xlim); \n",
    "        ylim = update_lims([np.min(trial[:,1]), np.max(trial[:,1])], ylim);\n",
    "        zlim = update_lims([np.min(trial[:,2]), np.max(trial[:,2])], zlim);\n",
    "        \n",
    "# create plot and set attributes\n",
    "fig = plt.figure(figsize = (9,7))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_xlim(xlim); ax.set_ylim(ylim); ax.set_zlim(zlim)\n",
    "plt.title('PCA State Space')\n",
    "ax.set_xlabel('PC0', fontsize = 20); ax.set_ylabel('PC1', fontsize = 20); ax.set_zlabel('PC2', fontsize = 20);\n",
    "\n",
    "# plot the line segments\n",
    "for condition in conditions:\n",
    "    \n",
    "    # for all trial-avged data\n",
    "    ax.add_collection3d(s_space_dict[condition]['line_collect'], zs=z, zdir='z')\n",
    "\n",
    "    # for trial group data\n",
    "    for trial_lc in s_space_dict[condition]['line_collect_trial'].values():\n",
    "        \n",
    "        ax.add_collection3d(trial_lc, zs=z, zdir='z')\n",
    "        \n",
    "ax.legend(['All Trial Avg','Trial 1-10 Avg','Trial 11-20 Avg',\n",
    "           'Trial 21-30 Avg','Trial 31-40 Avg','Trial 41-50 Avg']);\n",
    "\n",
    "# save plot\n",
    "fig_save_dir = 'C:\\\\Users\\\\stuberadmin\\\\Dropbox (Stuber Lab)\\\\Charles\\\\illustrator\\\\20200216_jUpdate_PCA\\\\'\n",
    "#matplotlib.pyplot.savefig(fig_save_dir + 'state_space_trial_group.pdf')\n",
    "\n",
    "#mpld3.save_html(fig, fig_save_dir + 'state_space_trial_group.html', template_type='simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from cycler import cycler\n",
    "matplotlib.rcParams['axes.prop_cycle'] = cycler(color='rb')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (13,4))\n",
    "\n",
    "for iPC in range(3):\n",
    "   \n",
    "    for condition in conditions:\n",
    "        ax[iPC].plot(data_dict['trial_tvec'], data_dict[condition]['Xt'][:,iPC])\n",
    "        ax[iPC].set_title(f'Time-Course of PC {iPC}', fontsize = 15)\n",
    "        if iPC == 0:\n",
    "            ax[iPC].set_ylabel('Fluorescence', fontsize = 15)\n",
    "            ax[iPC].set_xlabel('Time', fontsize = 15)\n",
    "            ax[iPC].legend(conditions, fontsize = 13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the PCA estimator attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make a figure with subplots of heatmaps\n",
    "def plot_img_vectorized_component(n_columns, data, original_dims):\n",
    "    \n",
    "    clims = [np.min(data), np.max(data)]\n",
    "    \n",
    "    num_comps = data.shape[0]\n",
    "    n_rows = int(np.ceil(num_comps/n_columns))\n",
    "   \n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=n_columns, figsize = (15, n_rows*4))\n",
    "    for iComp in range(num_comps):\n",
    "        \n",
    "        if n_rows == 1:\n",
    "            subplot_index = iComp\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(iComp, (n_rows, n_columns)) # turn int index to a tuple of array coordinates\n",
    "        \n",
    "        title = f\"PC {iComp}\"\n",
    "        pc_pixel_weights = data[iComp,:].reshape(original_dims[0],original_dims[1])\n",
    "\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], title, pc_pixel_weights, clims = clims)\n",
    "     \n",
    "    fig.colorbar(im, ax = ax, shrink = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each PC, plot the eigenvectors: weights/contribution of each pixel\n",
    "\n",
    "# makes plot non-interactable\n",
    "%matplotlib inline\n",
    "\n",
    "n_columns = 4\n",
    "plot_img_vectorized_component(n_columns, pca_xr_wrapper.estimator_.components_, data_dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the reconstructed activity maps look at the beginning and end of each condition for specific PCs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_windows = np.array([[-1, 0], [2, 3]])\n",
    "num_PCs = 1\n",
    "\n",
    "recon_map = {}\n",
    "\n",
    "for idx_window, analysis_window in enumerate(analysis_windows):\n",
    "\n",
    "    analysis_window_str = f\"{analysis_window[0]}_{analysis_window[1]}\"\n",
    "    recon_map[analysis_window_str] = {}\n",
    "\n",
    "    for idx_cond, condition in enumerate(conditions):\n",
    "\n",
    "        data_PC = data_dict[condition]['Xt'][utils.time_to_samples(data_dict['trial_tvec'], analysis_window, fs),:num_PCs]\n",
    "\n",
    "        eigenvector_PC = pca_xr_wrapper.estimator_.components_[:num_PCs,:]\n",
    "\n",
    "        recon_map[analysis_window_str][condition] = np.mean(np.matmul(data_PC,eigenvector_PC), axis=0).reshape(data_dims[0],data_dims[1])\n",
    "\n",
    "        if idx_window == 0 & idx_cond == 0:\n",
    "            recon_map['clims'] = update_lims([np.min(recon_map[analysis_window_str][condition]), np.max(recon_map[analysis_window_str][condition])])\n",
    "        else:\n",
    "            recon_map['clims'] = update_lims([np.min(recon_map[analysis_window_str][condition]), np.max(recon_map[analysis_window_str][condition])], recon_map['clims'])\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize = (10,10))\n",
    "for idx_window, analysis_window in enumerate(analysis_windows):\n",
    "    \n",
    "    analysis_window_str = f\"{analysis_window[0]}_{analysis_window[1]}\"\n",
    "    \n",
    "    for idx_cond, condition in enumerate(conditions):\n",
    "        title = f\"{analysis_window_str} sec; {condition}\"\n",
    "        im = utils.subplot_heatmap(axs[idx_window, idx_cond], title, recon_map[analysis_window_str][condition], clims = recon_map['clims'])\n",
    "\n",
    "fig.colorbar(im, ax = axs, shrink = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
