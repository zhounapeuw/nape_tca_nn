{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import h5py\n",
    "import utils\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import xarray # for organizing and storing the data \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" number of segments to split trials over. Ie. Because single trial plots in state space is noisy, \\n    let's break the trials up into groups and average to get less noisier signal.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indicate a file to analyze\n",
    "filename = 'VJ_OFCVTA_7_260_D6'\n",
    "root_dir = 'C:\\\\2pData\\\\Vijay data\\\\VJ_OFCVTA_7_D8_trained\\\\'\n",
    "sima_h5_path = root_dir + filename + '_sima_mc.h5'\n",
    "\n",
    "# set the sampling rate\n",
    "fs = 5\n",
    "trial_window = np.array([-1, 3]) # trial windowing in seconds relative to ttl-onset/trial-onset\n",
    "\n",
    "conditions = ['minus', 'plus_rewarded']\n",
    "\n",
    "num_avg_groups = 5.0 \n",
    "\"\"\" number of segments to split trials over. Ie. Because single trial plots in state space is noisy, \n",
    "    let's break the trials up into groups and average to get less noisier signal.\n",
    "\"\"\" ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_preprocess_data(fname, fpath, fs, trial_start_end_seconds, conditions, num_avg_groups)\n",
    "\n",
    "    data_snip = utils.load_h5(sima_h5_path)\n",
    "\n",
    "    data_dims = data_snip.shape\n",
    "    tvec = np.linspace(0, data_dims[2]/fs, data_dims[2])\n",
    "\n",
    "    #load behavioral data and trial info\n",
    "    glob_frame_files = glob.glob(root_dir + \"framenumberforevents*\") # look for a file in specified directory\n",
    "    frame_events = pickle.load( open( glob_frame_files[0], \"rb\" ), encoding=\"latin1\" ) # latin1 b/c original pickle made in python 2\n",
    "\n",
    "    trial_window_samp = trial_window*fs # turn trial start/end times to samples\n",
    "    data_dict= utils.extract_trial_data(data_snip, trial_window_samp[0], trial_window_samp[1],\n",
    "                                                           frame_events, conditions)\n",
    "\n",
    "    \"\"\"let's load data into xarray format, which has numerous \n",
    "    advantages over using numpy arrays, one of which is the ability \n",
    "    to assign names to dimensions rather than indexing by ints \"\"\"\n",
    "\n",
    "    for condition in conditions:\n",
    "\n",
    "        ypix_vec = range(0,data_dims[0])\n",
    "        xpix_vec = range(0,data_dims[1])\n",
    "        flattenpix_vec = range(0,data_dims[0]*data_dims[1])\n",
    "        trials_vec = range(data_dict[condition]['num_trials'])\n",
    "        trial_tvec = np.linspace(trial_window[0], trial_window[1], data_dict[condition]['num_samples'])\n",
    "\n",
    "        # xarray with dims: x,y,trial,samples\n",
    "        data_dict[condition]['xarr_data'] = xarray.DataArray(data_dict[condition]['data'], coords=[trials_vec, ypix_vec, xpix_vec, trial_tvec], dims=['trial', 'y', 'x', 'time'])\n",
    "\n",
    "        # flatten x and y pixels into one dimension\n",
    "        # reshape data and make xarray with dims: x-y,trial,samples\n",
    "        flatten_pix_trial_data = np.reshape(data_dict[condition]['data'], (len(trials_vec), data_dims[0]*data_dims[1], len(trial_tvec)))\n",
    "        data_dict[condition]['xarr_flatten_xy'] = xarray.DataArray( flatten_pix_trial_data, # this flattens only the x,y dimensions\n",
    "                                           coords=[trials_vec, flattenpix_vec, trial_tvec], \n",
    "                                           dims=['trial', 'yx', 'time'])\n",
    "\n",
    "        # average across trials\n",
    "        data_dict[condition]['xarr_flatten_pix_trialAvg'] = data_dict[condition]['xarr_flatten_xy'].mean(dim = 'trial')\n",
    "\n",
    "        ### https://stackoverflow.com/questions/43015638/xarray-reshape-data-split-dimension\n",
    "        # unstack trials into groups and average across trials (avged trials grouped by time)\n",
    "\n",
    "        num_trials_to_avg = data_dict[condition]['num_trials']/num_avg_groups\n",
    "\n",
    "        ind = pd.MultiIndex.from_product([np.arange(0, num_trials_to_avg), np.arange(0, num_avg_groups)],\n",
    "                                         names=['trials', 'trial_groups'])[np.arange(0, data_dict[condition]['num_trials'])] \n",
    "        # last arange cuts the index list if the number of trials per group does divide evenly into total num trials\n",
    "\n",
    "        data_dict[condition]['xarr_flatten_xy_group_trials'] = data_dict[condition]['xarr_flatten_xy'].assign_coords(trial=ind).unstack('trial').mean(dim = 'trials').transpose('trial_groups', 'yx', 'time')\n",
    "        ###\n",
    "\n",
    "    # pull out all trial-avged data for each cond, then average across conditions\n",
    "    data_dict['all_cond'] = {}\n",
    "\n",
    "    stacked_data = np.stack([data_dict[condition]['xarr_flatten_xy'].data \n",
    "                                                    for condition in conditions], axis = 0)\n",
    "    data_dict['all_cond']['flattenpix'] = stacked_data.reshape( data_shape[0]*data_shape[1], data_shape[2], data_shape[3]  )\n",
    "\n",
    "    data_dict['all_cond']['flattenpix_trial_cond_avg'] = np.average( [data_dict[condition]['xarr_flatten_pix_trialAvg'].data \n",
    "                                           for condition in conditions], axis=0)\n",
    "\n",
    "return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
