{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eScience Incubator Project: Data Analytics for Demixing and Decoding Patterns of Population Neural Activity Underlying Addiction Behavior \n",
    "\n",
    "### Charles Zhou, Research Scientist at the Center in Neurobiology of Addiction, Pain, and Emotion\n",
    "\n",
    "The aim of this project is to apply novel statistical and machine learning analysis techniques to large-scale 2-photon calcium imaging data with respect to addiction-related behaviors and assays.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](fig1.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\stuberadmin\\anaconda3\\envs\\escience_incubator\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# load dependencies\n",
    "import h5py\n",
    "import tensortools as tt # toolbox for TCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle # for loading behav data\n",
    "import utils\n",
    "import importlib as imp\n",
    "\n",
    "import xarray # for organizing and storing the data \n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn_xarray import wrap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate a file to analyze\n",
    "filename = 'VJ_OFCVTA_7_260_D6'\n",
    "root_dir = 'C:\\\\2pData\\\\Vijay data\\\\VJ_OFCVTA_7_D8_trained\\\\'\n",
    "sima_h5_path = root_dir + filename + '_sima_mc.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial windowing \n",
    "\n",
    "fs = 5\n",
    "trial_window = np.array([-1, 3]) # in seconds relative to ttl-onset/trial-onset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and preprocessing the data\n",
    "\n",
    "The data are in h5 (HDF5) format, which has the advantage of being able to load portions of the data into memory at a time. Below, we load the data, reorganize the dimensions, and convert it into x-array format. X-array is a python-unique data structure that allows for storage of meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_snip = utils.load_h5(sima_h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imaging data load\n",
    "data_h5file = h5py.File(sima_h5_path, 'r')\n",
    "data_h5file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h5file['imaging'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a snippit of data and get rid of un-needed singleton dimensions\n",
    "data_snip = np.squeeze(np.array(data_h5file['imaging'], dtype = int))\n",
    "data_snip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" typically it's good to have time as the last dimension because one doesn't usually iterate through time, so we'll\n",
    " reorganize the data dimension order\"\"\"\n",
    "\n",
    "print(data_snip.transpose(1,2,0).shape)\n",
    "\n",
    "data_snip = data_snip.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some meta data\n",
    "\n",
    "data_dims = data_snip.shape\n",
    "tvec = np.linspace(0, data_dims[2]/fs, data_dims[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's plot the first frame from the video snippit\n",
    "frame_num = 0\n",
    "to_plot = data_snip[:,:,frame_num]\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "plt.imshow(to_plot, cmap = 'gray')\n",
    "plt.title(f'Frame {frame_num}', fontsize = 20)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the behavioral data.\n",
    "\n",
    "During the brain recordings, animals perform a behavioral task (pavlovian conditioning) that allows for understanding how neural activity gives rise to memory encoding of rewards. The significance of examining this behavior is that addiction states are heavily based on associating a drug (unconditioned stimulus - US) to a particular cue (eg. heroin needle; conditioned stimulus - CS).\n",
    "\n",
    "The figure below (Namboodiri et al., 2019 Nature Neuroscience) shows the recording setup and task:\n",
    "\n",
    "![alt text](namboodiri_nn_fig1ab.png \"Title\")\n",
    "\n",
    "\n",
    "We ultimately want to reshape the data for a certain session (typically y_pixels, x_pixels, time/samples) to be amenable to trial-by-trial classifcation in a neural network. The resulting reshaped dimensions will be: trial, y_pixels, x_pixels, time/samples. So for a session with two behavioral conditions 50 trials each, 512x512, and 3 second trials (at 5 hz, that's 15 samples), our resulting array/tensor will be: 100 x 512 x 512 x 15. \n",
    "\n",
    "Since we have orders of magnitude more values for x and y pixels than samples, we will ultimately be performing dimensionality reduction to make the dataset more tractable. We will perform dimensionality reduction across y_pixels, x_pixels, and time/samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavioral data and trial info\n",
    "glob_frame_files = glob.glob(root_dir + \"framenumberforevents*\") # look for a file in specified directory\n",
    "frame_events = pickle.load( open( glob_frame_files[0], \"rb\" ), encoding=\"latin1\" ) # latin1 b/c original pickle made in python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw behavioral data organization\n",
    "\n",
    "Across the whole recording session, the animal is presented with randomized stimuli paired with or without sucrose rewards (each presentation is considered a trial). \n",
    "\n",
    "The time (ie. sample) at which each trial occurs relative to the beginning of the session is recorded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_key_len(dict_, key):\n",
    "    return len(dict_[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take start and end samples, make a vector of all values between, and repeat that vector num_rep times\n",
    "def make_tile(start_end, num_rep):\n",
    "    \n",
    "    samp_vec = np.arange(start_end[0], start_end[1]+1) # grab all samples between start/end\n",
    "\n",
    "    tile_array = np.tile(samp_vec,(num_rep,1))\n",
    "    \n",
    "    return tile_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate indices of each trial into an array for efficient trial extraction \n",
    "\n",
    "trial_window_samp = trial_window*fs # turn trial start/end times to samples\n",
    "\n",
    "conditions = ['plus_rewarded','minus']\n",
    "num_trials_cond = {}\n",
    "\n",
    "for idx, condition in enumerate(conditions):\n",
    "   \n",
    "    # convert window time bounds to samples and make a trial sample vector\n",
    "    # make an array where the sample indices are repeated in the y axis for n number of trials\n",
    "    num_trials_cond[condition] = dict_key_len(frame_events,condition)\n",
    "    \n",
    "    svec_tile = make_tile(trial_window_samp, num_trials_cond[condition])\n",
    "    num_trial_samps = svec_tile.shape[1]\n",
    "    \n",
    "    # now make a repeated matrix of each trial's ttl on sample in the x dimension\n",
    "    ttl_repmat = np.repeat(frame_events[condition][:,np.newaxis],num_trial_samps, axis = 1).astype('int')\n",
    "    \n",
    "    trial_sample_mat = ttl_repmat + svec_tile\n",
    "    \n",
    "    # extract frames in trials and reshape the data\n",
    "    reshape_dim = xarr_data.shape[:-1] + (svec_tile.shape)\n",
    "    data_trial = data_snip[:,:,np.ndarray.flatten(trial_sample_mat)].reshape( reshape_dim )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn trial-extracted data to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flatten_xy = np.reshape(data_snip, \n",
    "                             (data_dims[0]*data_dims[1], data_dims[2])) # this flattens only the x,y dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"let's load data into xarray format, which has numerous \n",
    "advantages over using numpy arrays, one of which is the ability \n",
    "to assign names to dimensions rather than indexing by ints \"\"\"\n",
    "\n",
    "condition = conditions[0]\n",
    "\n",
    "\n",
    "\n",
    "ypix_vec = range(0,data_dims[0])\n",
    "xpix_vec = range(0,data_dims[1])\n",
    "flattenpix_vec = range(0,data_dims[0]*data_dims[1])\n",
    "trials_vec = range(num_trials_cond[condition])\n",
    "trial_tvec = np.linspace(trial_window[0], trial_window[1], num_trial_samps)\n",
    "\n",
    "xarr_data = xarray.DataArray(data_trial, coords=[ypix_vec, xpix_vec, trials_vec, trial_tvec], dims=['y', 'x', 'trial', 'time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_pix_trial_data = np.reshape(data_trial, (data_dims[0]*data_dims[1], len(trials_vec), len(trial_tvec)))\n",
    "\n",
    "xarr_flatten_xy = xarray.DataArray( flatten_pix_trial_data, # this flattens only the x,y dimensions\n",
    "                                   coords=[flattenpix_vec, trials_vec, trial_tvec], \n",
    "                                   dims=['yx', 'trial', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across trials\n",
    "xr_avg_trial = xarr_data.mean(dim = 'trial')\n",
    "xr_flatten_pix_trial = xarr_flatten_xy.mean(dim = 'trial')\n",
    "xr_flatten_pix_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_flatten_pix_trial.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca_xr_wrapper = wrap(PCA(n_components=3), reshapes='yx') # create PCA object and specify dimension to perform PCA on\n",
    "\n",
    "Xt = pca_xr_wrapper.fit_transform(xr_flatten_pix_trial.transpose()) # fit/transform estimator; transpose to apply PCA on pixels\n",
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(trial_tvec,Xt)\n",
    "plt.title('Time-Course of First PCs', fontsize = 15)\n",
    "plt.ylabel('Fluorescence', fontsize = 15)\n",
    "plt.xlabel('Time', fontsize = 15)\n",
    "plt.legend(['PC0', 'PC1', 'PC2'], fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the PCA estimator attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in mean image and plots \n",
    "def subplot_heatmap(axs, title, image, clims=None, zoom_window=None):\n",
    "\n",
    "    im = axs.imshow(image, cmap='seismic')\n",
    "    axs.set_title(title, fontsize = 20)\n",
    "    \n",
    "    if zoom_window is not None:\n",
    "        im.set_clim(vmin=clims[0], vmax=clims[1])\n",
    "    \n",
    "    if zoom_window is not None:\n",
    "        \n",
    "        axs.set_title(title, fontsize = 20)\n",
    "        axs.axis(zoom_window)\n",
    "        axs.invert_yaxis()\n",
    "    axs.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_xr_wrapper.estimator_.explained_variance_\n",
    "num_comps = pca_xr_wrapper.estimator_.n_components_\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=num_comps, figsize=(15, 10))\n",
    "for iPC in range(num_comps):\n",
    "    \n",
    "    title = f\"PC {iPC}\"\n",
    "    pc_pixel_weights = pca_xr_wrapper.estimator_.components_[iPC,:].reshape(data_dims[0],data_dims[1])\n",
    "    \n",
    "    subplot_heatmap(ax[iPC], title, pc_pixel_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make synthetic dataset.\n",
    "I, J, K, R = 25, 25, 25, 4  # dimensions and rank\n",
    "X = tt.randn_ktensor((I, J, K), rank=R).full()\n",
    "X += np.random.randn(I, J, K)  # add noise\n",
    "\n",
    "# Fit CP tensor decomposition (two times).\n",
    "U = tt.cp_als(X, rank=R, verbose=True)\n",
    "V = tt.cp_als(X, rank=R, verbose=True)\n",
    "\n",
    "# Compare the low-dimensional factors from the two fits.\n",
    "fig, _, _ = tt.plot_factors(U.factors)\n",
    "tt.plot_factors(V.factors, fig=fig)\n",
    "\n",
    "# Align the two fits and print a similarity score.\n",
    "sim = tt.kruskal_align(U.factors, V.factors, permute_U=True, permute_V=True)\n",
    "print(sim)\n",
    "\n",
    "# Plot the results again to see alignment.\n",
    "fig, ax, po = tt.plot_factors(U.factors)\n",
    "tt.plot_factors(V.factors, fig=fig)\n",
    "\n",
    "# Show plots.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
