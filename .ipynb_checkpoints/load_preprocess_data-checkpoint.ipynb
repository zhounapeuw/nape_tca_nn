{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import h5py\n",
    "import utils\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import xarray # for organizing and storing the data \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate a file to analyze\n",
    "fname = 'VJ_OFCVTA_7_260_D6'\n",
    "fdir = 'C:\\\\2pData\\\\Vijay data\\\\VJ_OFCVTA_7_D8_trained\\\\'\n",
    "sima_h5_path = os.path.join(fdir, fname + '_sima_mc.h5')\n",
    "\n",
    "# set the sampling rate\n",
    "fs = 5\n",
    "trial_start_end_seconds = np.array([-1, 3]) # trial windowing in seconds relative to ttl-onset/trial-onset\n",
    "\n",
    "conditions = ['minus', 'plus_rewarded']\n",
    "\n",
    "\"\"\" number of segments to split trials over. Ie. Because single trial plots in state space is noisy, \n",
    "    let's break the trials up into groups and average to get less noisier signal.\n",
    "\"\"\" \n",
    "num_avg_groups = 5.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_data(fname, fdir, fs, trial_start_end_seconds, conditions, num_avg_groups):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a numpy 2d array and a subplot location, and plots a heatmap at the subplot location without axes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : string\n",
    "        file name\n",
    "\n",
    "    fdir : string\n",
    "        root file directory\n",
    "\n",
    "    fs : float\n",
    "        Sampling rate of the recording\n",
    "\n",
    "    trial_start_end_seconds : list \n",
    "        list with two float entries. First \n",
    "    \n",
    "    conditions : list\n",
    "        list of strings that correspond to the behavioral conditions to be analyzed \n",
    "    \n",
    "    num_avg_groups : int\n",
    "        Number of segments to split and average the trials over. Ie. Because single trial plots in state space is noisy, \n",
    "        we break the trials up into groups and average to get less noisier signal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_dict : dictionary\n",
    "            1st level of dict keys: individual conditions + condition combined data\n",
    "                2nd level of keys :\n",
    "                    data : numpy 4d array with dimensions (trials,y,x,samples)\n",
    "                    num_samples : number of samples (time) in a trial\n",
    "                    num_trials : total number of trials in the condition\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data_snip = utils.load_h5(sima_h5_path)\n",
    "\n",
    "    data_dims = data_snip.shape\n",
    "    tvec = np.linspace(0, data_dims[2]/fs, data_dims[2])\n",
    "\n",
    "    #load behavioral data and trial info\n",
    "    try:\n",
    "        glob_frame_files = glob.glob(fdir + \"framenumberforevents*\") # look for a file in specified directory\n",
    "        frame_events = pickle.load( open( glob_frame_files[0], \"rb\" ), encoding=\"latin1\" ) # latin1 b/c original pickle made in python 2\n",
    "    except:\n",
    "        print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "        \n",
    "    # with trial start/end samples, \n",
    "    trial_window_samp = trial_window*fs # turn trial start/end times to samples\n",
    "    data_dict= utils.extract_trial_data(data_snip, trial_window_samp[0], trial_window_samp[1],\n",
    "                                                           frame_events, conditions)\n",
    "\n",
    "    \"\"\"let's load data into xarray format, which has numerous \n",
    "    advantages over using numpy arrays, one of which is the ability \n",
    "    to assign names to dimensions rather than indexing by ints \"\"\"\n",
    "\n",
    "    for condition in conditions:\n",
    "        \n",
    "        # create index vectors for data dimensions; xarrayy stores these indices (eg. encodes time in seconds in place of samples)\n",
    "        ypix_vec = range(0,data_dims[0])\n",
    "        xpix_vec = range(0,data_dims[1])\n",
    "        flattenpix_vec = range(0,data_dims[0]*data_dims[1])\n",
    "        trials_vec = range(data_dict[condition]['num_trials'])\n",
    "        trial_tvec = np.linspace(trial_window[0], trial_window[1], data_dict[condition]['num_samples'])\n",
    "\n",
    "        # xarray with dimensions: x,y,trial,samples\n",
    "        data_dict[condition]['xarr_data'] = xarray.DataArray(data_dict[condition]['data'], coords=[trials_vec, ypix_vec, xpix_vec, trial_tvec], dims=['trial', 'y', 'x', 'time'])\n",
    "\n",
    "        # flatten x and y pixels into one dimension\n",
    "        # reshape data and make xarray with dims: x-y,trial,samples\n",
    "        flatten_pix_trial_data = np.reshape(data_dict[condition]['data'], (len(trials_vec), data_dims[0]*data_dims[1], len(trial_tvec)))\n",
    "        data_dict[condition]['xarr_flatten_xy'] = xarray.DataArray( flatten_pix_trial_data, # this flattens only the x,y dimensions\n",
    "                                           coords=[trials_vec, flattenpix_vec, trial_tvec], \n",
    "                                           dims=['trial', 'yx', 'time'])\n",
    "\n",
    "        # average across trials\n",
    "        data_dict[condition]['xarr_flatten_pix_trialAvg'] = data_dict[condition]['xarr_flatten_xy'].mean(dim = 'trial')\n",
    "\n",
    "        ### https://stackoverflow.com/questions/43015638/xarray-reshape-data-split-dimension\n",
    "        # unstack trials into groups and average across trials (avged trials grouped by time)\n",
    "\n",
    "        num_trials_to_avg = data_dict[condition]['num_trials']/num_avg_groups\n",
    "\n",
    "        # need to create a pandas multi-index to tell xarray the target dimensions to unpack into\n",
    "        ind = pd.MultiIndex.from_product([np.arange(0, num_trials_to_avg), np.arange(0, num_avg_groups)],\n",
    "                                         names=['trials', 'trial_groups'])[np.arange(0, data_dict[condition]['num_trials'])] \n",
    "        # last arange cuts the index list if the number of trials per group does divide evenly into total num trials\n",
    "\n",
    "        data_dict[condition]['xarr_flatten_xy_group_trials'] = data_dict[condition]['xarr_flatten_xy'].assign_coords(trial=ind).unstack('trial').mean(dim = 'trials').transpose('trial_groups', 'yx', 'time')\n",
    "        ###\n",
    "\n",
    "    # pull out all trial-avged data for each cond, then average across conditions\n",
    "    data_dict['all_cond'] = {}\n",
    "    \n",
    "    # make an array with dimensions trials, xy_pixels, samples where trials from all conditions are stacked in the first dimension\n",
    "    stacked_data = np.stack([data_dict[condition]['xarr_flatten_xy'].data \n",
    "                                                    for condition in conditions], axis = 0)\n",
    "    data_dict['all_cond']['flattenpix'] = stacked_data.reshape( data_shape[0]*data_shape[1], data_shape[2], data_shape[3]  )\n",
    "\n",
    "    data_dict['all_cond']['flattenpix_trial_cond_avg'] = np.average( [data_dict[condition]['xarr_flatten_pix_trialAvg'].data \n",
    "                                           for condition in conditions], axis=0)\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
